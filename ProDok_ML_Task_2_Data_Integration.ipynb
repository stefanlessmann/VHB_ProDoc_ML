{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProDok-ML Task 2 Data Integration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanlessmann/VHB_ProDoc_ML/blob/master/ProDok_ML_Task_2_Data_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsNxFYgkph__",
        "colab_type": "text"
      },
      "source": [
        "# Setup Notebook for Task 2\n",
        "This notebook is provided to download and integrate the data sets for the second task of the mini-assignemnt, namely the Kaggle home credit data set, which represents a binary classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTcNL1VEaRU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries that we will use. \n",
        "# You might need to install these libraries if you are running the notebook on your own machine.\n",
        "import numpy as np \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cshSAKOz9eHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from google.colab import files\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZwMkrpAKul0",
        "colab_type": "text"
      },
      "source": [
        "First, we need to load the data for this task from Kaggle. In order to do so, you will be required to have a Kaggle account and you need to accept the rules of the Home Credit Default Risk challenge here: https://www.kaggle.com/c/home-credit-default-risk/rules. Kaggle will ask you to verify your account via SMS in the scope of the registration. Course participants who cannot comply with this step should [email the course organizer](http://bit.ly/slessmann) \n",
        "\n",
        "There are two ways to obtain the data once the above steps have been completed. First, you can use the Kaggle API to download the data sets. This is the best approach when running the notebook in google colab. Alternatively, you can  manually download the data files from kaggle and load the datasets yourself. This is the preferred approach when running the notebook on your own computer. The following parts will illustrate both approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf0wNXYRYxSg",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle API - Download data directly into Colab\n",
        "\n",
        "If you plan to use the Kaggle API, you need to create and download your API token from the Kaggle account page. To do this, go to your kaggle account page, scroll down to the panel entitled API and click *Create New API Token* ![](https://drive.google.com/uc?export=view&id=1gvLwKHsRU2DfDD9YqICovHF7uNhfTGHM) \n",
        "\n",
        "This step will let you download a token, which is basically just a file *kaggle.json'. Store the file on your hard disk and upload it to colab using the below code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPV83mlCEgE0",
        "colab_type": "code",
        "outputId": "d7092fb1-aead-4fd3-faac-fb499eab5d2c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# First run the cell to create a data input form. \n",
        "# Afterwards, you can upload the kaggle API token (kaggle.json) using that form.\n",
        "# You may have to run this cell twice if an error pops up\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d309e15-460d-4f4d-a56b-727e138e681c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3d309e15-460d-4f4d-a56b-727e138e681c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHA5X-5TFv60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also run this cell\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGrpDqpFkPM5",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to load the different datasets of the home credit competition from kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6mQ9YI-kSNn",
        "colab_type": "code",
        "outputId": "732e8029-718d-4147-82b4-3b20c377aaa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "# Run this command, the data sets should be downloaded to the google colab server.\n",
        "# You will see some warnings about using an outdated API version. Just ignore them.\n",
        "!kaggle competitions download -c home-credit-default-risk "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading application_train.csv.zip to /content\n",
            " 91% 33.0M/36.1M [00:01<00:00, 13.0MB/s]\n",
            "100% 36.1M/36.1M [00:01<00:00, 32.3MB/s]\n",
            "Downloading bureau.csv.zip to /content\n",
            " 98% 36.0M/36.8M [00:00<00:00, 34.5MB/s]\n",
            "100% 36.8M/36.8M [00:00<00:00, 44.4MB/s]\n",
            "Downloading HomeCredit_columns_description.csv to /content\n",
            "  0% 0.00/36.5k [00:00<?, ?B/s]\n",
            "100% 36.5k/36.5k [00:00<00:00, 36.2MB/s]\n",
            "Downloading installments_payments.csv.zip to /content\n",
            " 96% 259M/271M [00:05<00:00, 38.0MB/s]\n",
            "100% 271M/271M [00:06<00:00, 46.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/524k [00:00<?, ?B/s]\n",
            "100% 524k/524k [00:00<00:00, 173MB/s]\n",
            "Downloading previous_application.csv.zip to /content\n",
            " 88% 67.0M/76.3M [00:01<00:00, 42.1MB/s]\n",
            "100% 76.3M/76.3M [00:01<00:00, 58.3MB/s]\n",
            "Downloading credit_card_balance.csv.zip to /content\n",
            " 84% 81.0M/96.7M [00:01<00:00, 47.8MB/s]\n",
            "100% 96.7M/96.7M [00:01<00:00, 83.3MB/s]\n",
            "Downloading bureau_balance.csv.zip to /content\n",
            " 99% 56.0M/56.8M [00:00<00:00, 44.5MB/s]\n",
            "100% 56.8M/56.8M [00:00<00:00, 61.0MB/s]\n",
            "Downloading application_test.csv.zip to /content\n",
            "  0% 0.00/5.81M [00:00<?, ?B/s]\n",
            "100% 5.81M/5.81M [00:00<00:00, 93.5MB/s]\n",
            "Downloading POS_CASH_balance.csv.zip to /content\n",
            " 92% 100M/109M [00:02<00:00, 29.4MB/s] \n",
            "100% 109M/109M [00:02<00:00, 38.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdZ4ZgCpaeqF",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the data manually from Kaggle\n",
        "Using the kaggle API is probably easier but it is definitly also possible to download the data manually from kaggle. Recall that the data we need is from the [Kaggle Home Credit Risk Competition](https://www.kaggle.com/c/home-credit-default-risk). The competition data comprises several individual files out of which we will need:\n",
        "\n",
        "* application_train.csv\n",
        "* application_test.csv\n",
        "* buerau.csv\n",
        "* previous_application.csv\n",
        "\n",
        "You will not need to unzip the data files but they must be available on your hard drive. The following codes assume that the data is avalable in the current working directory. To see this, note that we call the *read_csv* function without a path. Instead, we simply put in the name of the file to load. You might need to adjust these calls to ensure that *read_csv* is able to locate the data on your hard drive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzUOygVtrVBe",
        "colab_type": "text"
      },
      "source": [
        "## Processing the data\n",
        "No matter whether you downloaded the data manually or have used the kaggle API, you should now have the data available and be ready process the data using the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkYmIY2cZMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the following, we load the kaggle data; specifically the four files mentioned above. \n",
        "# You may need to adjust the code so that Python can find the data files on your hard drive.\n",
        "appl_train = pd.read_csv('application_train.csv.zip').add_prefix('app_').rename(columns={\"app_TARGET\": \"TARGET\", \"app_SK_ID_CURR\": \"SK_ID_CURR\"})\n",
        "appl_test = pd.read_csv('application_test.csv.zip').add_prefix('app_').rename(columns={\"app_SK_ID_CURR\": \"SK_ID_CURR\"})\n",
        "bureau = pd.read_csv('bureau.csv.zip').add_prefix('bur_').rename(columns={\"bur_SK_ID_CURR\": \"SK_ID_CURR\"})\n",
        "prev = pd.read_csv('previous_application.csv.zip').add_prefix('pre_').rename(columns={\"pre_SK_ID_CURR\": \"SK_ID_CURR\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY6-eBcRvdkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "30a1601c-41e0-4676-c47f-ebe2cf85c58f"
      },
      "source": [
        "# Show variables in memory and the dimensionality of the four loaded data sets\n",
        "%whos\n",
        "print('\\nDimensionality of the different data files:')\n",
        "print('Application Train' + str(appl_train.shape) + ' ' + str(appl_train.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Application Test' + str(appl_test.shape) + ' ' + str(appl_test.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Bureau' + str(bureau.shape)  + ' ' + str(bureau.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Previous app.' + str(prev.shape)  + ' ' + str(prev.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable             Type         Data/Info\n",
            "-------------------------------------------\n",
            "app_keep             list         n=27\n",
            "appl_test            DataFrame           SK_ID_CURR  ... ap<...>48744 rows x 121 columns]\n",
            "appl_train           DataFrame            SK_ID_CURR  ...  <...>07511 rows x 122 columns]\n",
            "bur_keep             list         n=13\n",
            "bureau               DataFrame             SK_ID_CURR  bur_<...>716428 rows x 17 columns]\n",
            "convert_obj_to_cat   function     <function convert_obj_to_cat at 0x7f02120d6400>\n",
            "files                module       <module 'google.colab.fil<...>s/google/colab/files.py'>\n",
            "np                   module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "pd                   module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "pre_keep             list         n=30\n",
            "prev                 DataFrame             pre_SK_ID_PREV  <...>670214 rows x 37 columns]\n",
            "tmp                  DataFrame            SK_ID_CURR  ...  <...>307511 rows x 27 columns]\n",
            "uploaded             dict         n=1\n",
            "x                    str          pre_SELLERPLACE_AREA\n",
            "\n",
            "Dimensionality of the different data files:\n",
            "Application Train(307511, 122) 543 MB\n",
            "Application Test(48744, 121) 85 MB\n",
            "Bureau(1716428, 17) 512 MB\n",
            "Previous app.(1670214, 37) 1913 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-4zXB6Buqzb",
        "colab_type": "text"
      },
      "source": [
        "The data is quite large. Depending on the resources you have available, it could easily exhaust the compute power of your machine. Therefore, we will now remove several variables. Note that this is a major simplification. In practice, we could not simply drop them but would need to check first which variables are important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZLs_BpvRvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variables to be kept among the application data\n",
        "app_keep = ['SK_ID_CURR', 'TARGET', 'app_DAYS_BIRTH', 'app_AMT_ANNUITY', 'app_AMT_CREDIT', 'app_AMT_GOODS_PRICE', 'app_AMT_INCOME_TOTAL', \n",
        "            'app_CODE_GENDER', 'app_DAYS_ID_PUBLISH', 'app_DAYS_LAST_PHONE_CHANGE', 'app_DAYS_REGISTRATION', \n",
        "            'app_EMERGENCYSTATE_MODE', 'app_EXT_SOURCE_1', 'app_EXT_SOURCE_2', 'app_EXT_SOURCE_3', 'app_FLAG_EMP_PHONE', \n",
        "            'app_FLAG_WORK_PHONE', 'app_DAYS_EMPLOYED', 'app_NAME_CONTRACT_TYPE', 'app_NAME_EDUCATION_TYPE', \n",
        "            'app_NAME_HOUSING_TYPE', 'app_NAME_INCOME_TYPE', 'app_OCCUPATION_TYPE', 'app_ORGANIZATION_TYPE', \n",
        "            'app_REG_CITY_NOT_WORK_CITY', 'app_REGION_RATING_CLIENT', 'app_REGION_RATING_CLIENT_W_CITY']  \n",
        "appl_train = appl_train[app_keep]\n",
        "appl_test = appl_test[[app_keep[0]] + app_keep[-24:-1]] # recall that the test data does not include the target variable\n",
        "\n",
        "# Variables to be kept among the bureau data\n",
        "bur_keep = ['SK_ID_CURR', 'bur_SK_ID_BUREAU', 'bur_CREDIT_ACTIVE', 'bur_AMT_ANNUITY', \n",
        "            'bur_CREDIT_DAY_OVERDUE', 'bur_AMT_CREDIT_SUM_DEBT', 'bur_AMT_CREDIT_SUM_LIMIT', \n",
        "            'bur_AMT_CREDIT_SUM_OVERDUE','bur_CREDIT_DAY_OVERDUE', 'bur_CREDIT_TYPE', 'bur_DAYS_CREDIT', \n",
        "            'bur_DAYS_CREDIT_ENDDATE', 'bur_DAYS_CREDIT_UPDATE']  \n",
        "bureau = bureau[bur_keep]\n",
        "\n",
        "# Variables to be kept among the previous application data\n",
        "pre_keep = ['SK_ID_CURR', 'pre_SK_ID_PREV', 'pre_AMT_ANNUITY', 'pre_AMT_APPLICATION', 'pre_AMT_CREDIT', 'pre_AMT_DOWN_PAYMENT', \n",
        "            'pre_AMT_GOODS_PRICE', 'pre_CHANNEL_TYPE', 'pre_CNT_PAYMENT',  \n",
        "            'pre_CODE_REJECT_REASON', 'pre_DAYS_DECISION', 'pre_DAYS_FIRST_DUE', 'pre_DAYS_LAST_DUE', 'pre_DAYS_TERMINATION',\n",
        "            'pre_HOUR_APPR_PROCESS_START', 'pre_NAME_CASH_LOAN_PURPOSE', 'pre_NAME_CLIENT_TYPE', 'pre_NAME_CONTRACT_STATUS',\n",
        "            'pre_NAME_CONTRACT_TYPE', 'pre_NAME_GOODS_CATEGORY', 'pre_NAME_PAYMENT_TYPE', 'pre_NAME_PORTFOLIO',\n",
        "            'pre_NAME_PRODUCT_TYPE', 'pre_NAME_SELLER_INDUSTRY', 'pre_NAME_TYPE_SUITE', 'pre_NAME_YIELD_GROUP', \n",
        "            'pre_PRODUCT_COMBINATION', 'pre_RATE_DOWN_PAYMENT', 'pre_RATE_INTEREST_PRIVILEGED', 'pre_SELLERPLACE_AREA']\n",
        "prev = prev[pre_keep]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcpeRmmjSeAz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "If you wish, you can rerun the previous code after execute the following cell Just for illustration, I have copied the above code to display the amount of data in memory. Running it will show you how the above operation has reduced the amount of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-oxQY-VOVvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2741fade-9db3-4895-c3e2-92aebe352611"
      },
      "source": [
        "# Show once more the dimensionality and size of our dataframes\n",
        "print('\\nDimensionality of the different data files:')\n",
        "print('Application Train' + str(appl_train.shape) + ' ' + str(appl_train.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Application Test' + str(appl_test.shape) + ' ' + str(appl_test.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Bureau' + str(bureau.shape)  + ' ' + str(bureau.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')\n",
        "print('Previous app.' + str(prev.shape)  + ' ' + str(prev.memory_usage(index=True, deep=True).sum()//1024//1024)+' MB')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensionality of the different data files:\n",
            "Application Train(307511, 27) 199 MB\n",
            "Application Test(48744, 24) 30 MB\n",
            "Bureau(1716428, 13) 363 MB\n",
            "Previous app.(1670214, 30) 1642 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Y3PJnJyObh",
        "colab_type": "text"
      },
      "source": [
        "Next, we perform some datatype preprocessing. Pandas version 1.x can do this automatically, older versions cannot. So make sure to have the right version installed on your computer if you do not use colab.\n",
        "\n",
        "In a nutshell, the codes first develops a function to convert columns in a data set to a suitable data type. The purpose is to save memory. Afterwards, we apply to function to each of the four data sets just loaded. Do not worry about further details but make sure that you execute both of the following code cells, that defining the function and that calling the function for each of the data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8wsif5av__I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert columns with type \"object\" to type \"category\"\n",
        "def convert_obj_to_cat(data):  \n",
        "  obj_cols = [x for x in data.columns if data[x].dtype=='object']\n",
        "  flag_cols = [x for x in data.columns if data[x].dtype=='int64']\n",
        "  flag_cols = [x for x in flag_cols if np.abs(data[x]).max()==1]\n",
        "  data[obj_cols] = data[obj_cols].astype('category')\n",
        "  data[flag_cols] = data[flag_cols].astype('int8')\n",
        "  int_cols = [x for x in data.columns if data[x].dtype=='int64']\n",
        "  float_cols = [x for x in data.columns if data[x].dtype=='float64']\n",
        "  data[int_cols] = data[int_cols].astype('int32')\n",
        "  data[float_cols] = data[float_cols].astype('float32')\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcZADGaYoWyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appl_train = convert_obj_to_cat(appl_train)\n",
        "appl_test = convert_obj_to_cat(appl_test)\n",
        "prev = convert_obj_to_cat(prev)\n",
        "#@Elias: this did not work for me for some unknown reason.\n",
        "# whereas bureau.select_dtypes(...) worked fine\n",
        "#bureau = convert_obj_to_cat(bureau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWVV4ds2yZeH",
        "colab_type": "text"
      },
      "source": [
        "Finally, we store  the data in a [h5 file](https://www.h5py.org/). This file format allows storing huge amounts of data in a single file in an efficient manner. \n",
        "\n",
        "If you are running the notebook on google colab, you can also download the h5 file by clicking on the folder icon on the sidebar and right-clicking on the data.h5 file and selecting download. \n",
        "\n",
        "In our second modeling task, we will work with the h5 file so make sure to have it ready before moving on to [the actual task](). \n",
        "\n",
        "**Colab must download the data or store it in their Google drive if applicable. If you do not store your data, your data will be deleted after some time and you will need to repeat the previous steps.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Zjwgwrwepi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appl_train.to_hdf('data.h5', key='appl_train', mode='w', format='t')\n",
        "appl_test.to_hdf('data.h5', key='appl_test', format='t')\n",
        "bureau.to_hdf('data.h5', key='bureau', format='t')\n",
        "prev.to_hdf('data.h5', key='prev', format='t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiDauhD527uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is an example how colab users can copy the h5 file to their google drive if applicable\n",
        "!cp 'data.h5' '/content/drive/My Drive/ProDok'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8LfpboKfXlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "c4fbe18d-4a41-481a-e528-2a206d840ff8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}